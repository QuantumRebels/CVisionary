# ğŸš€ CVisionary
**âœ¨ Your Dream Job, One Resume Away âœ¨**  

ğŸ¯ Craft AI-optimized resumes that match job descriptions, generate professionally formatted content, and score higher in Applicant Tracking Systems (ATS). Built with cutting-edge technology including React 19, Vite, Tailwind CSS, and powerful LLM integration.

---

## âœ¨ Key Features

- ğŸ” **OAuth Login** (LinkedIn, GitHub)
- ğŸ” **LinkedIn & GitHub Scraper**
- ğŸ¯ **AI-Powered Resume Matching** with job descriptions
- ğŸ§  **LLM-Powered Resume Generation**
- ğŸ“„ **PDF/LaTeX Export Support**
- âœï¸ **Editable Resume Preview**
- ğŸ“Š **Resume Scoring System**
- ğŸ’¡ **AI-Based Resume Improvement Suggestions**
- ğŸ† **ATS-Friendly Output**

---

## ğŸ› ï¸ Tech Stack

| Tech            | Purpose                                      |
|-----------------|----------------------------------------------|
| React 19        | Frontend Framework                           |
| Vite            | Lightning-fast dev server                    |
| Tailwind CSS    | Utility-first styling                        |
| Shadcn/ui       | UI Components                                |
| Lucide-react    | Icon library                                 |
| Framer Motion   | Animations                                   |
| Node.js + Express | Backend APIs                              |
| MongoDB         | Vector DB / Resume Storage                   |
| OpenAI / Gemini | LLM for resume generation                    |
| Python 3.10+    | AI/ML microservices (Embedding, Generation)  |
| FastAPI         | AI/ML API framework                          |
| Sentence-Transformers | Embeddings generation             |
| FAISS-CPU       | In-memory vector search                      |
| scikit-learn    | ATS scoring model                            |

---

## ğŸ“ Project Structure
```
ğŸ“ root/
â”œâ”€â”€ ğŸ“ backend/
â”‚   â”œâ”€â”€ ğŸ“ controllers/
â”‚   â”œâ”€â”€ ğŸ“ routes/
â”‚   â”œâ”€â”€ ğŸ“ utils/          # Contains LLM prompts, scraping logic, etc.
â”‚   â””â”€â”€ server.js
â”œâ”€â”€ ğŸ“ frontend/
â”‚   â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ components/ # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ ğŸ“ pages/      # Route-based pages
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ main.jsx
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ ğŸ“ ai-services/        # AI/ML microservices (Embedding, Generator, Scoring)
â”‚   â”œâ”€â”€ ğŸ“ embedding_service/
â”‚   â”œâ”€â”€ ğŸ“ generator_service/
â”‚   â””â”€â”€ ğŸ“ scoring_service/
â”œâ”€â”€ .env
â”œâ”€â”€ README.md
â””â”€â”€ package.json
```

---

## ğŸ–¥ï¸ Pages and Routes

| Route              | Page Name               | Description                           |
| ------------------ | ----------------------- | ------------------------------------- |
| `/`                | Landing Page            | App intro, login buttons              |
| `/dashboard`       | Dashboard               | Overview & scraping/resume status     |
| `/connect`         | LinkedIn/GitHub Connect | OAuth & scraping                      |
| `/job-description` | Job Description Input   | Enter target JD                       |
| `/resume-preview`  | Resume Output + Editing | AI-generated resume + edits           |
| `/ai-improver`     | Resume AI Improver Page | Get suggestions to improve the Resume |

---

## ğŸ¤– AI Integration

The AI/ML portion consists of three lightweight microservices that operate alongside the existing backend:

1. **Embedding Service**

   * Chunks user profile text (experiences, projects, skills) into small pieces.
   * Uses a sentence-transformer model (e.g., `all-MiniLM-L6-v2`) to convert each chunk (and incoming job descriptions) into 384-dimensional vectors.
   * Indexes these vectors in an in-memory FAISS index (persisted in a local SQLite database).
   * Exposes endpoints to (a) generate embeddings for arbitrary text and (b) retrieve the top-K most relevant profile chunks for a given job-description embedding.

2. **Resume Generator Service**

   * Receives the retrieved profile chunks and job-description embedding.
   * Forms a Retrieval-Augmented Generation (RAG) prompt that combines â€œmust-haveâ€ job keywords with the most relevant user passages.
   * Invokes an LLM (either a local LLaMA/Mistral checkpoint or OpenAI/Gemini) to produce concise, job-tailored bullet points.

3. **ATS Scoring Service**

   * Takes the generated bullet points plus job-description features.
   * Computes simple features such as keyword overlap and semantic similarity (via embeddings).
   * Uses a lightweight scikit-learn classifier (e.g., logistic regression) to return an â€œATS match scoreâ€ and a few short improvement suggestions if the score is below a threshold.

> **Note:** Each AI/ML service runs locally on a separate port (e.g., 8001, 8002, 8003) using FastAPI and can be containerized via Docker Compose. When deployed to GCP, these can be migrated to Cloud Run or Vertex AI endpoints without changing the overall flow.

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/QuantumRebels/CVisionary.git
cd CVisionary
```

### 2. Setup the Frontend

```bash
cd frontend
npm install
npm run dev
```

### 3. Setup the Backend

```bash
cd backend
npm install
npm run dev
```

---

### 4. Setup & Run the AI/ML Services

1. **Embedding Service**

   ```bash
   cd ai-services/embedding_service
   pip install -r requirements.txt
   # Ensure a local SQLite DB (e.g., embeddings.db) is in place or will be created on startup
   uvicorn app:app --reload --port 8001
   ```

   * **Endpoints:**

     * `POST /index/{userId}` â†’ Fetches structured profile JSON, chunks it, generates embeddings, and indexes in FAISS.
     * `POST /embed` â†’ Returns an embedding for any input text.
     * `POST /retrieve/{userId}` â†’ Returns the top-K profile chunks for a given query embedding.

2. **Resume Generator Service**

   ```bash
   cd ai-services/generator_service
   pip install -r requirements.txt
   uvicorn app:app --reload --port 8002
   ```

   * **Endpoint:**

     * `POST /generate/{userId}` â†’ Accepts a job-description string, retrieves top profile chunks, assembles a RAG prompt, and calls an LLM to produce tailored bullet points.

3. **ATS Scoring Service**

   ```bash
   cd ai-services/scoring_service
   pip install -r requirements.txt
   uvicorn app:app --reload --port 8003
   ```

   * **Endpoint:**

     * `POST /score` â†’ Accepts the job-description and generated bullet points, computes features, and returns an ATS match score and short improvement suggestions.

> **Tip:** If you donâ€™t have each directory in place yet, create them under `ai-services/` and copy the relevant service code (FastAPI app, models, etc.) into them. Each service uses its own `.env` file for configuration, as shown below.

---

## âš™ï¸ Environment Variables

**Backend (.env in `backend/`):**

```bash
MONGODB_URL=
LINKEDIN_API_KEY=...
GITHUB_API_KEY=...
OPENAI_API_KEY=...
```

**Embedding Service (`ai-services/embedding_service/.env`):**

```bash
SQLITE_PATH=./embeddings.db
MODEL_NAME=all-MiniLM-L6-v2
```

**Generator Service (`ai-services/generator_service/.env`):**

```bash
LLM_MODEL_PATH=/path/to/local-llama-model.bin  # or leave blank to use OpenAI/Gemini
OPENAI_API_KEY=...
```

**Scoring Service (`ai-services/scoring_service/.env`):**

```bash
ATS_MODEL_PATH=/path/to/ats_model.pkl
```

---

## ğŸ“„ License

[MIT](https://choosealicense.com/licenses/mit/)

---

## ğŸ‘©â€ğŸ’» Developed By

**Team QuantumRebels**  
ğŸ’« Made With Passion & Cutting-Edge AI  
ğŸ¯ Helping You Land Your Dream Job, One Resume at a Time!  

> "The future belongs to those who believe in the beauty of their dreams." - Eleanor Roosevelt  
ğŸ’™ Best of luck on your job search journey! ğŸš€

```